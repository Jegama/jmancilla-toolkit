{"docstore/data": {"2ef03385-4ec9-4565-90c4-c3aa3b576866": {"__data__": {"id_": "2ef03385-4ec9-4565-90c4-c3aa3b576866", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2765212e-f454-4928-9386-f0da815ca9f2", "node_type": null, "metadata": {}, "hash": "d6613f5e2f1215af9e0b9dc008f1caecfe69af6c5e90c5e18a5ada39130ef5fa"}}, "hash": "d6613f5e2f1215af9e0b9dc008f1caecfe69af6c5e90c5e18a5ada39130ef5fa", "text": "CALVINIST PARROT\n\nThe Calvinist Parrot project was an ambitious initiative to introduce an AI-powered chatbot that would allow users to delve deeper into the Bible from the perspective of Reformed theology. The project's primary goal was to offer users a thoughtful, accurate, and insightful response to any queries about the Scriptures. To accomplish this, the project developed an AI duo, Parrot and Calvin, to provide users with an exceptional experience while exploring religious texts. In addition, the chatbot is designed to be a learning tool that continuously evolves and improves to enhance user interactions and deepen their understanding of religious texts. By providing such an innovative tool, the Calvinist Parrot project has enabled users to gain a deeper understanding of the Bible and Reformed theology in a user-friendly and accessible manner.\n\nGOAL\nDevelop an AI-driven chatbot capable of providing thoughtful, accurate, and insightful responses to queries about the Bible from a Reformed theology perspective.\nContinually improve the AI's understanding and response capabilities to facilitate a deeper exploration of the Scriptures for users.\n\nSOLUTIONS\nThe solution was an AI chatbot developed using two GPT agents working in tandem. The AI duo, Parrot and Calvin, were trained in many texts, including religious texts, commentary, and historical context. In addition, the chatbot's responses were curated and calibrated to align with the principles of Reformed theology, ensuring the guidance provided was accurate and insightful.\n\nA feedback loop was integrated into the system to ensure continuous learning and improvement of the chatbot. First, users could provide feedback on the chatbot's responses, which were then used to improve its understanding and response generation. The system was also designed to evolve, with a librarian AI planned to join the team to offer additional support and resources.\n\nFINDINGS\nThe primary findings from this project were:\nThe AI chatbot successfully provided accurate and insightful responses to user queries, enhancing their understanding of the Bible from a Reformed theology perspective.\nThe feedback loop effectively refined the AI's responses, leading to a noticeable improvement in the chatbot's understanding and guidance over time.\n\nTAKEAWAYS\nThe Calvinist Parrot project highlighted the potential of AI technology in enhancing the understanding of complex subjects like religious texts. The success of the AI duo, Parrot and Calvin, underscores the power of collaborative AI systems in providing comprehensive and accurate responses. The project also underlined the importance of continual learning and improvement in AI systems facilitated by effective feedback mechanisms.", "start_char_idx": 0, "end_char_idx": 2746, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "59e81914-8cca-4226-9a90-9773fc693ebd": {"__data__": {"id_": "59e81914-8cca-4226-9a90-9773fc693ebd", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "09ba2b83-f038-45af-b4b8-805d6cfcf8a8", "node_type": null, "metadata": {}, "hash": "ba6c099fd221e65856a5a22d367c51753e9cc9b1fdb0ee2b5d9a5c3222915035"}}, "hash": "ba6c099fd221e65856a5a22d367c51753e9cc9b1fdb0ee2b5d9a5c3222915035", "text": "CUSTOMER SUPPORT BOT\n\nMy goal was to improve customer support by introducing an autonomous agent capable of handling user inquiries. I aimed to create a 'Solution Spotlight' feature that offered users clear and concise responses to their queries. This approach would reduce the workload on the call center, improve self-service, and ultimately increase customer satisfaction. This AI agent is powered by advanced ML technology, including embeddings and GPT-3.5, and is supported by an all-encompassing index of all the articles available on a Customer Support site. This innovative approach ensures that users receive prompt, accurate, and relevant responses to their inquiries without human intervention.\n\nGOAL\nDevelop an autonomous agent that can provide a 'solution spotlight' - a curated 'best answer' - to user queries.\nImprove customer self-service and reduce the number of calls to the call center.\n\nSOLUTIONS\nThis solution involved the development of an autonomous agent using LangChain, a powerful tool. Our first step was indexing all the Customer Support site articles and creating a comprehensive library catalog. With over 322 articles indexed, our system thoroughly understood the available content. \n\nNext, we employed \"embeddings\" to search for the most relevant content. Embeddings are numerical representations of words or phrases that capture their meaning. Whenever a user asks a question, we transform it into this numerical form and then search for the article with the closest matching numerical representation. \n\nOnce we've identified the most relevant article, we use an advanced AI model GPT-3.5 to generate a response. This AI has been trained on a vast amount of text from the internet and can generate human-like responses based on the information it has been trained on.\n\nFINDINGS\nThe main findings from this project were: TBD.\nThe autonomous agent successfully provided relevant and accurate responses to user queries, improving customer self-service.\nThe 'Solution Spotlight' feature was well-received by users, resulting in a noticeable reduction in calls to the call center.\n\nTAKEAWAYS\nThrough this project, I learned about the significance of employing advanced AI technologies to enhance customer support and the effectiveness of autonomous agents in dealing with customer inquiries. It also underscored the importance of a comprehensive indexing system for support articles and the usefulness of embeddings in searching for the most relevant information. Overall, this project demonstrated how AI can improve the customer experience and streamline support services.", "start_char_idx": 0, "end_char_idx": 2602, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "965cdeff-10c0-4a59-a33d-51913afeab79": {"__data__": {"id_": "965cdeff-10c0-4a59-a33d-51913afeab79", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "7984a170-84ee-4126-91a0-d9edcc0bb107", "node_type": null, "metadata": {}, "hash": "174ca6c218e187e3b2223acd24069b6a0077900fdab2f8ac311d283be0ac4f7c"}}, "hash": "bb6751193a4350c8f10ce0a6ba22fd3124c1fc782b49ae1762e29876c639c8c1", "text": "DESIGN RESEARCH\nOVERVIEW\nThis project aimed to have a better understanding of drivers in real-world scenarios. The goal was to create a stress elicitation technique that can be efficiently and reliably duplicated. We used both scripted in-vehicle stressor events and unscripted on-road stressors such as pedestrians and construction zones. An algorithm was used to identify windows where the participant was experiencing stress and validated using participant self-report.\n\nPaper: Eliciting Driver Stress Using Naturalistic Driving Scenarios on Real Roads.\n\nGOAL\nPropose instrumentation that could be used to measure the driver experience and its validity for analysis.\nValidate a stress elicitation technique that could be replicated on the road and safe for drivers.\nModified display with low battery warnings.\n\nSOLUTIONS\nThe proposed approach was a mixed methodology, where the participant behavior was quantified using psychophysiological measurements and validated with interviews before, during, and after the experiment.\n\nThe experimental design can be described as follows: Participants drive up a windy, secluded mountain road with poor cellular reception. They are told that they have plenty of charge for the study. Unbeknownst to the driver, we installed an experimental display that gives visual and auditory warnings of low battery charge 15 minutes into their drive. After 22 minutes of driving, the screen shows' empty', and the car demands to pull over to the side of the road. At this point, the driver attempts to call the research team.\n\nAn open API of the algorithm was released.\n\nFINDINGS\nThe two main results were:\nThe eliciting technique was successfully replicated, and 90% of participants experienced stress.\n89% of the stress events were correlated with road events.\n\nGiven the nature of these kinds of experiments, having scripted and unscripted events gives a better picture of how automotive drivers react to different stimuli.\n\nTAKEAWAYS\nThis experiment's biggest takeaways were having open communication with everyone involved and driving meaningful research in all stages, particularly with the follow-up. And given the hybrid nature of this research, the collaboration between different areas of expertise was valuable.", "start_char_idx": 0, "end_char_idx": 2253, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "2583657d-1a7b-47ea-a302-c28cdcfd8d3d": {"__data__": {"id_": "2583657d-1a7b-47ea-a302-c28cdcfd8d3d", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "13cf81cb-6eff-4373-8b59-955d971d33e5", "node_type": null, "metadata": {}, "hash": "6f52de985a2e3f7f180fe82e27a15767280fe5db0ea120577f6306a910004d42"}}, "hash": "f017ba59898f1fa350cff2fd9bc17031a545cf1411fea79ec95bde1ef5f2395a", "text": "ML PORTFOLIO\nI have evolved from a Quant UX researcher to a Machine Learning Engineer throughout my career through continuous learning and adaptation. My user experience and quantitative research background has given me a unique perspective on machine learning. I aim to create technically sound ML models with practical applications while keeping the users at the center of my approach. My diverse range of projects attests to my expertise and skills in machine learning.\n\nMODULAR SURVEY ANALYSIS SYSTEM\nThe Modular Survey Analysis System is a significant upgrade to the automatic report generator I initially developed for handling weekly, monthly, and quarterly surveys. This project, which will span four months starting in June 2023, aims to create a flexible and efficient system for analyzing survey data. The system was designed to increase output with fewer resources and provide a scalable solution for analyzing various surveys with diverse question sets. The main goal was to enable the team to analyze surveys in minutes, significantly improving efficiency and productivity.\n\nThe project was divided into three phases. The first phase focused on developing a modular report generator, automating the classification of familiar question types. The second phase incorporated context-aware survey logic and plot generation, enabling the system to analyze surveys with more complex structures. The final phase fine-tuned the plots generated by the system and expanded its capabilities to include other types of survey questions. By the end of the project, the Modular Survey Analysis System had become a robust and versatile tool capable of handling a broad range of survey structures and complexities, providing more comprehensive analysis capabilities.\n\nCALVINIST PARROT\nThe Calvinist Parrot project exemplified the incredible potential of AI in enhancing user engagement with religious texts. Through rigorous development, I created an AI-powered chatbot duo named Parrot and Calvin, which was explicitly trained on various texts, including religious commentary and historical context. Its ultimate goal was to provide users with thoughtful, accurate, and insightful responses to their inquiries about the Scriptures from a Reformed theology perspective.\n\nTo ensure that Parrot and Calvin provided the best possible guidance, I created a feedback loop that allowed continuous learning and improvement. By utilizing user feedback, we were able to refine the chatbot's understanding and response generation, ensuring that its guidance remained accurate, insightful, and aligned with the principles of Reformed theology.\n\nCUSTOMER SUPPORT BOT\nI aimed to improve customer support with the help of cutting-edge AI technology. I developed an autonomous agent that could provide prompt and concise responses to user queries, thereby reducing the workload on our call center and improving self-service for our users. \n\nI used advanced AI technologies like embeddings and GPT-3.5 to power the agent. I also created a comprehensive index of all the articles on a CS site, in this case, Roku, to ensure users could easily access the most relevant information. The development process involved indexing all the support site articles and creating a library catalog. Next, I used embeddings to search for the most relevant content and then utilized the advanced AI model of GPT-3.5 to generate a response. This has greatly improved the efficiency of our customer support system, allowing us to provide faster and more accurate solutions to our users.", "start_char_idx": 0, "end_char_idx": 3548, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "11680f1c-b19d-429b-a04a-a0d494dd0dad": {"__data__": {"id_": "11680f1c-b19d-429b-a04a-a0d494dd0dad", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f234f235-3431-43c5-be70-919f11567812", "node_type": null, "metadata": {}, "hash": "6a7d0040be684974f691806aaaefb60c0431625a5facb4bd98a382a0005db5d9"}}, "hash": "9377e4e21576117aa22adcf1f663a3bcf5c65f132deb02f6e7a6a9d06aa42e4f", "text": "RESEARCH OPERATIONS\n\nSuccessful leadership starts with a person that lives to serve others. I have had the privilege to teach trainees and lead research teams in academia and international groups throughout my carrier. The challenges are the same in both worlds: communication is vital for success. One of the most successful projects across multiple companies has been the standardization of reports and consolidation, leading to higher visibility for the research team across numerous teams.\n\nSOLUTION\nOne of the most common problems I have encountered is that highly skilled people often don't have the necessary visibility to present their results. Having a centralized tool to share the information and the findings has been advantageous to show progress and increase collaboration. \n\nHowever, adoption has been an issue on different occasions. Not everyone is on board to try new things; I have handled this to do a progressive rollout. I start with my immediate team, where I have a better rapport with the researchers, and I present it as a \"pilot,\" with no strings attached. Once the first results and improvements started to surface, I onboarded more teams to leverage the research team's work for the rest of the UX org. \n\nRESULTS\nThe results were noteworthy. The team created a repository with all the research and once it started getting traction with the rest of the teams across the org, looking through our knowledge base became self-served. \n\nAnother advantage was the visualization tools; it helped the leadership glance at the projects' current state. As a result, it a result, it a result, it helps them make informed decisions about where the project lacks or needs more resources. For example, the visualization below helps them to know what projects need more attention on a given day.\n\nTAKEAWAYS\nThe added process and documentation needed to standardize the team's work is a complicated hurdle to overcome. But once the team starts seeing the benefit of having a searchable repository, it encourages them to socialize it with others.\n\nChange can be knotty for people, and imposing tools doesn't help. Therefore, a successful manager should find a progressive rollout considering their team.", "start_char_idx": 0, "end_char_idx": 2214, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "c3ad9bc8-ffb9-4e57-8344-a3f78adf3063": {"__data__": {"id_": "c3ad9bc8-ffb9-4e57-8344-a3f78adf3063", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "a0499373-8e84-4663-b1d8-201ff072bcc9", "node_type": null, "metadata": {}, "hash": "7a45b4cad1e371de37132c5f6e944f9c1470e3ee0ec70ed04464297e4a76630d"}}, "hash": "7a45b4cad1e371de37132c5f6e944f9c1470e3ee0ec70ed04464297e4a76630d", "text": "RESEARCH PORTFOLIO\nI have worked as a researcher since 2009, starting in behavioral sciences, later working on Human-Computer interaction (HCI), and now as a Senior UX researcher. My work can be classified into three main areas extended below. I have had the pleasure of applying my knowledge to product design and development in different companies and leading impactful research that reaches millions of users.\n\nDESIGN RESEARCH\nFrom experimental design to algorithm validation, I advocate for real-world testing that can complement the in-lab settings. I have been involved in exciting projects to improve multiple products, from wearables and consumer goods to mobile devices and 10-foot experiences. Conducting state-of-the-art research; can help us improve the experience of more people. In addition, by doing research, we can find the information needed to improve the product and give metrics that can help us benchmark our progress.\n\nMy main goal is to translate research findings into actionable recommendations. This is by designing lean experiments that can be replicated and tailored to understand the user and answer business questions. I advocate having behavioral log data to have large-scale patterns and in-depth knowledge through interviewing people to understand the \"how\" and \"why\" of their behavior.\n\nUSER RESEARCH\nGiven my hybrid background (psychology-computer science), this has been the most exciting part of my work. Understanding user behavior and creating digital solutions that will enhance their lives. I have experience in all the product's life cycle, from the early stages to the final products serving thousands of users.\n\nGeneral skills:\nUsability testing (field, in-lab, remote)\nPrototyping (low- and high-fidelity)\nSurveys (Design and analysis)\nInterviews\nUser Personas\n\nRESEARCH OPS\nSuccessful leadership starts with a person that lives to serve others. I have had the privilege to teach trainees and lead research teams in academia and international groups throughout my carrier. The challenges are the same in both worlds: communication is vital for success. One of the most successful projects across multiple companies has been the standardization of reports and consolidation, leading to higher visibility for the research team across numerous teams.", "start_char_idx": 0, "end_char_idx": 2293, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "8eee5f23-52ae-410b-ab16-9d507d9ef431": {"__data__": {"id_": "8eee5f23-52ae-410b-ab16-9d507d9ef431", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "0a82edbf-d6e7-408a-82fe-e7159afb7f9c", "node_type": null, "metadata": {}, "hash": "3129077cb660d46b6da6232f584a989c069c9aceca316394c10e854f7f5099b6"}}, "hash": "3129077cb660d46b6da6232f584a989c069c9aceca316394c10e854f7f5099b6", "text": "ABOUT ME\nWith my extensive experience as a Quantitative UX Researcher and Machine Learning Engineer, I have specialized abilities that allow me to succeed in creating expansive language models and implementing machine learning algorithms and user research. My previous projects, including creating an AI-powered chatbot Calvinist Parrot and the autonomous Roku Support Bot, are a testament to my proficiency in leveraging AI to enhance user experiences. Moreover, my ability to develop a stress detection algorithm for real-world driving scenarios illustrates my expertise in applying machine learning in complex situations. I am committed to continuous learning and innovation, which motivates me to keep abreast of the latest technological advancements and make meaningful improvements in user-centered design.\n\n\nEXPERIENCE\nRoku Inc. \nSenior User Experience Researcher\nJuly 2022 - Present.\n\nUser Experience Researcher\nJanuary 2021 - July 2022\n\nDeveloped a Python-based dashboard to automate statistical analysis and reporting of UX metrics, coded scripts for automating data analysis from surveys, and created tools to generate reports based on the output.\n\nConducted quantitative evaluations on remote controls, leveraging behavioral log analysis from 70+ million devices.\n\n\u2013\nWalmart Labs,\nSenior User Experience Researcher\nJuly 2019 - Nov 2020\n\nConnected business metrics and interaction analytics to prioritize research using a data-driven strategy, presenting synthesized research findings to diverse stakeholders.\n\nEvaluated user experience through qualitative and quantitative research, enabling designers to create human-centered experiences while advocating for users within an interdisciplinary team.\n\n\u2013\nScrapworks inc.\nData Scientist\nSeptember 2017 - August 2019\n\nDeveloped an interactive dashboard to visualize and filter 20 years of sales data, resulting in a 30% sales growth.\n\nResearched RNNs for custom recommendations and forecasting, reducing mean absolute error by 60%.\n\n\u2013\nSuggestic\nSenior User experience researcher\nDecember 2016 - September 2017\n\nLed the transition from a conversational to a graphical interface, integrating app features while balancing user needs and business requirements.\n\nDesigned storyboards, wireframes, and prototypes to define and lead user engagement metrics.\n\n\u2013\nStanford University\nUser experience researcher\nMay 2016 - November 2016\n\nConducted UX research to design, experiment, and collect 150+ hours of car, biometric, and video data from real-world environments.\n\nPerformed signal processing and statistical analysis of physiological data, developing innovative algorithms to identify the emotional states of automobile drivers with approximately 90% accuracy.\n\n\u2013\nGoogle.org\nUser experience researcher\nJanuary 2016 - June 2016\n\nAnalyzed technology adoption through a longitudinal ethnographic study, inspiring complex changes in multiple use cases.\n\n\u2013\nITAM\nUser experience researcher\nAugust 2014 - May 2016\n\nDelivered customized solutions for multiple interactive systems (wearable, mobile, web) and conducted usability testing at different development stages.\n\nGenerated custom data visualization, psychophysiological signal analysis, and user-interface design within multiple 10-person teams to identify user behavior patterns.\n\n\u2013\nUniversity of Colima\nHealth Psychology Researcher\n2009 - 2014\n\nDeveloped and assessed a psychoeducational program for adults with type 2 diabetes, improving glucose levels in 80% of patients.\n\n\u2013\nStevens Institute of Technology\nData science intern\nJune 2015 - August 2015\n\nDeveloped a visualization technique to classify over 2 million tweets into new depression-related categories.\n\nINTEREST\nUser Experience (UX)\n\nNatural Language Processing (NLP)\n\nData Analytics\n\nData Visualization\n\n\nEDUCATION\nInstituto Tecnol\u00f3gico Aut\u00f3nomo de M\u00e9xico\nComputer Science, M.S.\n2014-2016\n\n \n\nUniversidad de colima\nPsychology, B.A.\n2008-2013", "start_char_idx": 0, "end_char_idx": 3909, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "536fd66c-a677-4527-b818-457413fbf179": {"__data__": {"id_": "536fd66c-a677-4527-b818-457413fbf179", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f7a9c6a3-cbfb-4464-a28a-0c54bcfd7d96", "node_type": null, "metadata": {}, "hash": "d5cdd4b0d4a1e1bce1cd75367c2a3457e3bc5fbd19614d80bd4ad1e9dc80a72f"}}, "hash": "d5cdd4b0d4a1e1bce1cd75367c2a3457e3bc5fbd19614d80bd4ad1e9dc80a72f", "text": "SURVEY REPORT GENERATOR\n\nI developed an automatic report generator that takes a weekly survey and generates the report without human intervention. This entry explains the upgraded version.\n\nImplementing the Modular Survey Analysis System will significantly improve our team's report generator. With this new system, survey data analysis will be more flexible and efficient, allowing for faster results with fewer resources needed. This scalable solution will also be able to handle a variety of surveys with different question sets. Overall, the Modular Survey Analysis System will significantly enhance our ability to analyze survey data and provide valuable insights.\n\nGOAL\nThe main goal of this project is to enable the team to analyze surveys sent in minutes and increase the team's output with fewer available resources. \nThe system is designed to be flexible and adaptable, capable of handling multiple surveys with diverse question sets without requiring manual adjustments or hard-coding new questions.\n\nPHASE 1: \nDEVELOPING THE MODULAR REPORT GENERATOR\nDuring the initial stage of the project, I will focus on creating a modular report generator. Although the current automated report generator I developed for the weekly surveys is efficient, it faces limitations because of its hard-coded questions. This makes it less adaptable to handle various surveys with diverse questions. I intend to automate the classification of familiar questions to overcome this issue. This approach will enable us to test the algorithm's ability to classify various questions, providing a proof of concept for the system. By the end of this stage, the system will be able to categorize familiar questions into demographic, Likert scale, categorical (single select and multiple select), and open-ended categories. This foundational work will pave the way for more advanced features in subsequent stages.\n\nPHASE 2: \nIMPLEMENTING CONTEXT-AWARE SURVEY LOGIC AND PLOT GENERATION\nThe second phase will build on the foundation established in Phase 1. This phase will enhance the Modular Survey Analysis System by incorporating context-aware survey logic and plot generation. This will enable the system to analyze surveys with more complex structures and dependencies between questions, providing a deeper understanding of the data. \n\nFurthermore, the system will be developed to parse survey logic, identifying dependencies and relationships between questions. This will allow for context-aware plot generation that accurately represents the data, considering the relationships between questions and providing meaningful insights. Upon completion of Phase 2, the system will be capable of handling complex survey logic and generating context-aware plots.\n\nPHASE 3: \nENHANCING PLOT CUSTOMIZATION AND EXPANDING SURVEY QUESTION CAPABILITIES\nThe upcoming phase of this project will enhance the system's capabilities in generating plots and including other types of survey questions. Through this phase, the system will be more adaptable and customizable to meet specific analysis requirements, providing our organization with more value. The plots generated by the system will be optimized to ensure they accurately represent the data and provide insightful observations. Furthermore, expanding the system's capabilities to include ranking, matrix, and slider scale questions will enable the Modular Survey Analysis System to handle a broader range of survey structures and complexities, providing more comprehensive analysis capabilities.\n\nCONCLUSION\nThe team aims to completely transform how we approach survey analysis by implementing the Modular Survey Analysis System. By leveraging familiar questions and enhancing our existing reporting capabilities, we have created a reliable and flexible solution that has significantly increased our productivity while utilizing fewer resources. The versatility of this system allows it to be easily adapted for various surveys, making it a wise investment for our organization.", "start_char_idx": 0, "end_char_idx": 4003, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "3610bcd0-0c0a-4a87-ae9c-98268ebf7bf2": {"__data__": {"id_": "3610bcd0-0c0a-4a87-ae9c-98268ebf7bf2", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "fa7b6492-bf17-4399-ab37-cb7e7424063c", "node_type": null, "metadata": {}, "hash": "9fb777e856eebe0caf71fb5a75cf2a830ab2cf2df1f38d043caf8b992644a555"}}, "hash": "9fb777e856eebe0caf71fb5a75cf2a830ab2cf2df1f38d043caf8b992644a555", "text": "USER RESEARCH\n\nThe most exciting projects I have done are hardware-related, from wearable devices to self-driving cars. And as I had the opportunity to partner with outstanding researchers, I continued the work of understanding how people use their remote control and pilot metrics and systems to benchmark how much we have improved from previous iterations.\n\nGOALS\nEncode a framework for statistical analysis of the aggregate usability testing and behavioral log analysis.\nValidate the proposed metrics to gauge how devices stand between each other.\n\n\nINITIAL BASELINES\nThis project started in collaboration with a senior researcher who created the initial framework to evaluate the most common tasks users perform with their remote control while using their smart TVs. During a year, we conducted multiple usability studies to fine-tune the metrics and tasks, gathering data to run statistical tests to compare them.\n\nDuring this initial phase, I worked on the statistical analysis and gathered the behavioral logs to understand the aggregate usage of the 70+ million devices currently in use. \n\nEVOLUTION\nThe findings of this research led to a new remote launched in the Fall of '22. While this remote control was under hardware testing, I evaluated our remote controls, adding the button presses recorded during the studies. \n\nWhile evaluating other remote controls, additional features not previously included in the metrics were added, given that they are exclusive to some remotes. This evaluation included country-specific metrics and a dashboard to gauge the different behaviors per country and between remote controls, which have distinct features.\n\nTAKEAWAYS\nCollaborating with the designers and PMs was valuable in understanding what was most meaningful for them. In addition, it solidified our research, which led to a change in the direction of some decisions taken before having the data.\n\nGiven that this project continued intermittently for two years, having well-documented research and moderator guides and scripting the statistical analysis to optimize the work proved critical to delivering valuable results to our stakeholders.", "start_char_idx": 0, "end_char_idx": 2149, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}}, "docstore/ref_doc_info": {"2765212e-f454-4928-9386-f0da815ca9f2": {"node_ids": ["2ef03385-4ec9-4565-90c4-c3aa3b576866"], "metadata": {}}, "09ba2b83-f038-45af-b4b8-805d6cfcf8a8": {"node_ids": ["59e81914-8cca-4226-9a90-9773fc693ebd"], "metadata": {}}, "7984a170-84ee-4126-91a0-d9edcc0bb107": {"node_ids": ["965cdeff-10c0-4a59-a33d-51913afeab79"], "metadata": {}}, "13cf81cb-6eff-4373-8b59-955d971d33e5": {"node_ids": ["2583657d-1a7b-47ea-a302-c28cdcfd8d3d"], "metadata": {}}, "f234f235-3431-43c5-be70-919f11567812": {"node_ids": ["11680f1c-b19d-429b-a04a-a0d494dd0dad"], "metadata": {}}, "a0499373-8e84-4663-b1d8-201ff072bcc9": {"node_ids": ["c3ad9bc8-ffb9-4e57-8344-a3f78adf3063"], "metadata": {}}, "0a82edbf-d6e7-408a-82fe-e7159afb7f9c": {"node_ids": ["8eee5f23-52ae-410b-ab16-9d507d9ef431"], "metadata": {}}, "f7a9c6a3-cbfb-4464-a28a-0c54bcfd7d96": {"node_ids": ["536fd66c-a677-4527-b818-457413fbf179"], "metadata": {}}, "fa7b6492-bf17-4399-ab37-cb7e7424063c": {"node_ids": ["3610bcd0-0c0a-4a87-ae9c-98268ebf7bf2"], "metadata": {}}}, "docstore/metadata": {"2ef03385-4ec9-4565-90c4-c3aa3b576866": {"doc_hash": "d6613f5e2f1215af9e0b9dc008f1caecfe69af6c5e90c5e18a5ada39130ef5fa", "ref_doc_id": "2765212e-f454-4928-9386-f0da815ca9f2"}, "59e81914-8cca-4226-9a90-9773fc693ebd": {"doc_hash": "ba6c099fd221e65856a5a22d367c51753e9cc9b1fdb0ee2b5d9a5c3222915035", "ref_doc_id": "09ba2b83-f038-45af-b4b8-805d6cfcf8a8"}, "965cdeff-10c0-4a59-a33d-51913afeab79": {"doc_hash": "bb6751193a4350c8f10ce0a6ba22fd3124c1fc782b49ae1762e29876c639c8c1", "ref_doc_id": "7984a170-84ee-4126-91a0-d9edcc0bb107"}, "2583657d-1a7b-47ea-a302-c28cdcfd8d3d": {"doc_hash": "f017ba59898f1fa350cff2fd9bc17031a545cf1411fea79ec95bde1ef5f2395a", "ref_doc_id": "13cf81cb-6eff-4373-8b59-955d971d33e5"}, "11680f1c-b19d-429b-a04a-a0d494dd0dad": {"doc_hash": "9377e4e21576117aa22adcf1f663a3bcf5c65f132deb02f6e7a6a9d06aa42e4f", "ref_doc_id": "f234f235-3431-43c5-be70-919f11567812"}, "c3ad9bc8-ffb9-4e57-8344-a3f78adf3063": {"doc_hash": "7a45b4cad1e371de37132c5f6e944f9c1470e3ee0ec70ed04464297e4a76630d", "ref_doc_id": "a0499373-8e84-4663-b1d8-201ff072bcc9"}, "8eee5f23-52ae-410b-ab16-9d507d9ef431": {"doc_hash": "3129077cb660d46b6da6232f584a989c069c9aceca316394c10e854f7f5099b6", "ref_doc_id": "0a82edbf-d6e7-408a-82fe-e7159afb7f9c"}, "536fd66c-a677-4527-b818-457413fbf179": {"doc_hash": "d5cdd4b0d4a1e1bce1cd75367c2a3457e3bc5fbd19614d80bd4ad1e9dc80a72f", "ref_doc_id": "f7a9c6a3-cbfb-4464-a28a-0c54bcfd7d96"}, "3610bcd0-0c0a-4a87-ae9c-98268ebf7bf2": {"doc_hash": "9fb777e856eebe0caf71fb5a75cf2a830ab2cf2df1f38d043caf8b992644a555", "ref_doc_id": "fa7b6492-bf17-4399-ab37-cb7e7424063c"}}}